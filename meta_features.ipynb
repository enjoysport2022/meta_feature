{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import gc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur time = 2018/08/24 20:46:42\n",
      "(116624, 8847) (53093, 8847)\n",
      "cur time = 2018/08/24 20:46:46\n"
     ]
    }
   ],
   "source": [
    "print('cur time = ' + str(datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))\n",
    "train = np.load('../feature/train_fe_8_23.npy')\n",
    "test = np.load('../feature/test_fe_8_23.npy')\n",
    "train_labels = pd.read_csv('../feature/train_label.csv')['label'].values\n",
    "print train.shape,test.shape\n",
    "print('cur time = ' + str(datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:  0\n",
      "23327 93297\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0175478\tvalid_1's multi_logloss: 0.0264023\n",
      "[200]\ttraining's multi_logloss: 0.00275986\tvalid_1's multi_logloss: 0.016544\n",
      "[300]\ttraining's multi_logloss: 0.00109042\tvalid_1's multi_logloss: 0.0173074\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's multi_logloss: 0.00254555\tvalid_1's multi_logloss: 0.0165206\n",
      "FOLD:  1\n",
      "23327 93297\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0174761\tvalid_1's multi_logloss: 0.0253601\n",
      "[200]\ttraining's multi_logloss: 0.00262269\tvalid_1's multi_logloss: 0.0154576\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's multi_logloss: 0.00296962\tvalid_1's multi_logloss: 0.0153761\n",
      "FOLD:  2\n",
      "23325 93299\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0182342\tvalid_1's multi_logloss: 0.0219362\n",
      "[200]\ttraining's multi_logloss: 0.00298082\tvalid_1's multi_logloss: 0.0111156\n",
      "[300]\ttraining's multi_logloss: 0.00119553\tvalid_1's multi_logloss: 0.0113313\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's multi_logloss: 0.00213646\tvalid_1's multi_logloss: 0.0109764\n",
      "FOLD:  3\n",
      "23323 93301\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0178815\tvalid_1's multi_logloss: 0.0246319\n",
      "[200]\ttraining's multi_logloss: 0.00275777\tvalid_1's multi_logloss: 0.0146232\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's multi_logloss: 0.00286096\tvalid_1's multi_logloss: 0.0146037\n",
      "FOLD:  4\n",
      "23322 93302\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0172813\tvalid_1's multi_logloss: 0.02733\n",
      "[200]\ttraining's multi_logloss: 0.00246602\tvalid_1's multi_logloss: 0.0180053\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's multi_logloss: 0.00259383\tvalid_1's multi_logloss: 0.0179784\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(train_labels, n_folds=5, shuffle=True, random_state=42)\n",
    "meta_train = np.zeros(shape = (len(train),6))\n",
    "meta_test = np.zeros(shape = (len(test),6))\n",
    "\n",
    "for i,(tr_ind,te_ind) in enumerate(skf):\n",
    "    print 'FOLD: ',i\n",
    "    print len(te_ind),len(tr_ind)\n",
    "    X_train,X_train_label = train[tr_ind],train_labels[tr_ind]\n",
    "    X_val,X_val_label = train[te_ind],train_labels[te_ind]\n",
    "    dtrain = lgb.Dataset(X_train,X_train_label) \n",
    "    dval   = lgb.Dataset(X_val,X_val_label, reference = dtrain)   \n",
    "    params = {\n",
    "            'task':'train', \n",
    "            'boosting_type':'gbdt',\n",
    "            'num_leaves': 15,\n",
    "            'objective': 'multiclass',\n",
    "            'num_class':6,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.85,\n",
    "            'subsample':0.85,\n",
    "            'num_threads': 16,\n",
    "            'metric':'multi_logloss',\n",
    "            'seed':100\n",
    "        }  \n",
    "    model = lgb.train(params, dtrain, num_boost_round=100000,valid_sets=[dtrain,dval],verbose_eval=100, early_stopping_rounds=100)  \n",
    "    pred_val = model.predict(X_val)\n",
    "    pred_test = model.predict(test)\n",
    "    \n",
    "    meta_train[te_ind] = pred_val\n",
    "    meta_test += pred_test\n",
    "meta_test /= 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_pickle(meta_train,'../feature/train_meta_lgb_1.pkl')\n",
    "#pd.to_pickle(meta_test,'../feature/test_meta_lgb_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnn_1 = pd.read_pickle('../feature/train_meta_cnn.pkl')\n",
    "test_cnn_1 = pd.read_pickle('../feature/test_meta_cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lgb_1 = pd.read_pickle('../feature/train_meta_lgb_1.pkl')\n",
    "test_lgb_1 = pd.read_pickle('../feature/test_meta_lgb_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.hstack([train,train_cnn_1,train_lgb_1])\n",
    "test = np.hstack([test,test_cnn_1,test_lgb_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116624, 8859), (53093, 8859))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:  0\n",
      "23327 93297\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0132989\tvalid_1's multi_logloss: 0.0234082\n",
      "[200]\ttraining's multi_logloss: 0.0016545\tvalid_1's multi_logloss: 0.0172636\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's multi_logloss: 0.00294376\tvalid_1's multi_logloss: 0.0166835\n",
      "FOLD:  1\n",
      "23327 93297\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0133569\tvalid_1's multi_logloss: 0.022644\n",
      "[200]\ttraining's multi_logloss: 0.00160646\tvalid_1's multi_logloss: 0.015774\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's multi_logloss: 0.00259558\tvalid_1's multi_logloss: 0.0153602\n",
      "FOLD:  2\n",
      "23325 93299\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0140416\tvalid_1's multi_logloss: 0.0185739\n",
      "[200]\ttraining's multi_logloss: 0.00192878\tvalid_1's multi_logloss: 0.0103099\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttraining's multi_logloss: 0.00237546\tvalid_1's multi_logloss: 0.0102695\n",
      "FOLD:  3\n",
      "23323 93301\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0136545\tvalid_1's multi_logloss: 0.0214515\n",
      "[200]\ttraining's multi_logloss: 0.00178867\tvalid_1's multi_logloss: 0.0146032\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's multi_logloss: 0.00293975\tvalid_1's multi_logloss: 0.0142364\n",
      "FOLD:  4\n",
      "23322 93302\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.013111\tvalid_1's multi_logloss: 0.0242256\n",
      "[200]\ttraining's multi_logloss: 0.00147057\tvalid_1's multi_logloss: 0.017826\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's multi_logloss: 0.0023736\tvalid_1's multi_logloss: 0.0173736\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(train_labels, n_folds=5, shuffle=True, random_state=42)\n",
    "meta_train = np.zeros(shape = (len(train),6))\n",
    "meta_test = np.zeros(shape = (len(test),6))\n",
    "\n",
    "for i,(tr_ind,te_ind) in enumerate(skf):\n",
    "    print 'FOLD: ',i\n",
    "    print len(te_ind),len(tr_ind)\n",
    "    X_train,X_train_label = train[tr_ind],train_labels[tr_ind]\n",
    "    X_val,X_val_label = train[te_ind],train_labels[te_ind]\n",
    "    dtrain = lgb.Dataset(X_train,X_train_label) \n",
    "    dval   = lgb.Dataset(X_val,X_val_label, reference = dtrain)   \n",
    "    params = {\n",
    "            'task':'train', \n",
    "            'boosting_type':'gbdt',\n",
    "            'num_leaves': 15,\n",
    "            'objective': 'multiclass',\n",
    "            'num_class':6,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.85,\n",
    "            'subsample':0.85,\n",
    "            'num_threads': 16,\n",
    "            'metric':'multi_logloss',\n",
    "            'seed':100\n",
    "        }  \n",
    "    model = lgb.train(params, dtrain, num_boost_round=100000,valid_sets=[dtrain,dval],verbose_eval=100, early_stopping_rounds=100)  \n",
    "    pred_val = model.predict(X_val)\n",
    "    pred_test = model.predict(test)\n",
    "    \n",
    "    meta_train[te_ind] = pred_val\n",
    "    meta_test += pred_test\n",
    "meta_test /= 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_pickle(meta_train,'../feature/train_meta_lgb_2.pkl')\n",
    "#pd.to_pickle(meta_test,'../feature/test_meta_lgb_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Lambda, Embedding, Dropout, Activation,GRU,Bidirectional\n",
    "from keras.layers import Conv1D,Conv2D,MaxPooling2D,GlobalAveragePooling1D,GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM, SpatialDropout1D\n",
    "from keras.layers.merge import concatenate, Concatenate, Average, Dot, Maximum, Multiply, Subtract\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers.wrappers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "train_nn = pd.DataFrame(train).fillna(0.0).values\n",
    "test_nn = pd.DataFrame(test).fillna(0.0).values\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_nn)\n",
    "train_nn = ss.transform(train_nn)\n",
    "test_nn = ss.transform(test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(FE_LEN = 8859):\n",
    "    \n",
    "    _input = Input(shape=(FE_LEN,),dtype='float32')\n",
    "    fc = Dropout(0.25)(_input)\n",
    "    fc = BatchNormalization()(fc)\n",
    "    fc = Dense(256, activation='relu')(fc)\n",
    "    fc = Dropout(0.25)(fc)\n",
    "    fc = BatchNormalization()(fc)\n",
    "    fc = Dense(512, activation='relu')(fc)\n",
    "    fc = Dropout(0.25)(fc) \n",
    "    preds = Dense(6, activation = 'softmax')(fc)\n",
    "    \n",
    "    model = Model(inputs=_input, outputs=preds)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "    optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:  0\n",
      "23327 93297\n",
      "Train on 93297 samples, validate on 23327 samples\n",
      "Epoch 1/100\n",
      "93297/93297 [==============================] - 16s 177us/step - loss: 0.0842 - val_loss: 0.0300\n",
      "Epoch 2/100\n",
      "93297/93297 [==============================] - 15s 159us/step - loss: 0.0237 - val_loss: 0.0301\n",
      "Epoch 3/100\n",
      "93297/93297 [==============================] - 15s 158us/step - loss: 0.0191 - val_loss: 0.0290\n",
      "Epoch 4/100\n",
      "93297/93297 [==============================] - 15s 162us/step - loss: 0.0162 - val_loss: 0.0311\n",
      "Epoch 5/100\n",
      "93297/93297 [==============================] - 15s 159us/step - loss: 0.0145 - val_loss: 0.0339\n",
      "Epoch 6/100\n",
      "93297/93297 [==============================] - 15s 158us/step - loss: 0.0138 - val_loss: 0.0290\n",
      "Epoch 7/100\n",
      "93297/93297 [==============================] - 15s 160us/step - loss: 0.0128 - val_loss: 0.0312\n",
      "Epoch 8/100\n",
      "93297/93297 [==============================] - 15s 159us/step - loss: 0.0110 - val_loss: 0.0354\n",
      "Epoch 9/100\n",
      "93297/93297 [==============================] - 15s 161us/step - loss: 0.0106 - val_loss: 0.0346\n",
      "FOLD:  1\n",
      "23327 93297\n",
      "Train on 93297 samples, validate on 23327 samples\n",
      "Epoch 1/100\n",
      "93297/93297 [==============================] - 17s 181us/step - loss: 0.0676 - val_loss: 0.0305\n",
      "Epoch 2/100\n",
      "93297/93297 [==============================] - 14s 147us/step - loss: 0.0242 - val_loss: 0.0278\n",
      "Epoch 3/100\n",
      "93297/93297 [==============================] - 13s 139us/step - loss: 0.0178 - val_loss: 0.0281\n",
      "Epoch 4/100\n",
      "93297/93297 [==============================] - 14s 154us/step - loss: 0.0158 - val_loss: 0.0314\n",
      "Epoch 5/100\n",
      "93297/93297 [==============================] - 14s 155us/step - loss: 0.0147 - val_loss: 0.0306\n",
      "FOLD:  2\n",
      "23325 93299\n",
      "Train on 93299 samples, validate on 23325 samples\n",
      "Epoch 1/100\n",
      "93299/93299 [==============================] - 16s 172us/step - loss: 0.0762 - val_loss: 0.0302\n",
      "Epoch 2/100\n",
      "93299/93299 [==============================] - 14s 149us/step - loss: 0.0243 - val_loss: 0.0273\n",
      "Epoch 3/100\n",
      "93299/93299 [==============================] - 14s 150us/step - loss: 0.0194 - val_loss: 0.0264\n",
      "Epoch 4/100\n",
      "93299/93299 [==============================] - 14s 152us/step - loss: 0.0163 - val_loss: 0.0279\n",
      "Epoch 5/100\n",
      "93299/93299 [==============================] - 14s 148us/step - loss: 0.0144 - val_loss: 0.0297\n",
      "Epoch 6/100\n",
      "93299/93299 [==============================] - 14s 146us/step - loss: 0.0136 - val_loss: 0.0271\n",
      "FOLD:  3\n",
      "23323 93301\n",
      "Train on 93301 samples, validate on 23323 samples\n",
      "Epoch 1/100\n",
      "93301/93301 [==============================] - 15s 164us/step - loss: 0.0960 - val_loss: 0.0286\n",
      "Epoch 2/100\n",
      "93301/93301 [==============================] - 13s 142us/step - loss: 0.0234 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "93301/93301 [==============================] - 14s 150us/step - loss: 0.0200 - val_loss: 0.0244\n",
      "Epoch 4/100\n",
      "93301/93301 [==============================] - 14s 149us/step - loss: 0.0164 - val_loss: 0.0263\n",
      "Epoch 5/100\n",
      "93301/93301 [==============================] - 14s 145us/step - loss: 0.0145 - val_loss: 0.0263\n",
      "Epoch 6/100\n",
      "93301/93301 [==============================] - 14s 150us/step - loss: 0.0134 - val_loss: 0.0263\n",
      "FOLD:  4\n",
      "23322 93302\n",
      "Train on 93302 samples, validate on 23322 samples\n",
      "Epoch 1/100\n",
      "93302/93302 [==============================] - 16s 171us/step - loss: 0.0865 - val_loss: 0.0340\n",
      "Epoch 2/100\n",
      "93302/93302 [==============================] - 13s 144us/step - loss: 0.0226 - val_loss: 0.0317\n",
      "Epoch 3/100\n",
      "93302/93302 [==============================] - 14s 145us/step - loss: 0.0185 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "93302/93302 [==============================] - 14s 150us/step - loss: 0.0150 - val_loss: 0.0334\n",
      "Epoch 5/100\n",
      "93302/93302 [==============================] - 14s 152us/step - loss: 0.0133 - val_loss: 0.0364\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "skf = StratifiedKFold(train_labels, n_folds=5, shuffle=True, random_state=42)\n",
    "train_labels_nn = pd.get_dummies(train_labels).values\n",
    "meta_train = np.zeros(shape = (len(train),6))\n",
    "meta_test = np.zeros(shape = (len(test),6))\n",
    "model_name = 'mlp_raw_feature_v1'\n",
    "for i,(tr_ind,te_ind) in enumerate(skf):\n",
    "    print 'FOLD: ',i\n",
    "    print len(te_ind),len(tr_ind)\n",
    "    X_train,X_train_label = train_nn[tr_ind],train_labels_nn[tr_ind]\n",
    "    X_val,X_val_label = train_nn[te_ind],train_labels_nn[te_ind] \n",
    "    \n",
    "    model_save_path = '../model_weight/{}.hdf5'.format(model_name)\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model_checkpoint = ModelCheckpoint(model_save_path, save_best_only=True, save_weights_only=True)\n",
    "    model = MLP()\n",
    "    model.fit(X_train,X_train_label,\n",
    "                  validation_data=(X_val,X_val_label),\n",
    "                  epochs=100,batch_size=512,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[early_stopping,model_checkpoint]\n",
    "            )\n",
    "    pred_val = model.predict(X_val)\n",
    "    pred_test = model.predict(test_nn)\n",
    "    \n",
    "    meta_train[te_ind] = pred_val\n",
    "    meta_test += pred_test\n",
    "meta_test /= 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(meta_train,'../feature/train_meta_mlp_1.pkl')\n",
    "pd.to_pickle(meta_test,'../feature/test_meta_mlp_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_2(FE_LEN = 8859):\n",
    "    \n",
    "    _input = Input(shape=(FE_LEN,),dtype='float32')\n",
    "    fc = Dropout(0.25)(_input)\n",
    "    fc = BatchNormalization()(fc)\n",
    "    fc = Dense(256, activation='relu')(fc)\n",
    "    fc = Dropout(0.25)(fc)\n",
    "    fc = BatchNormalization()(fc)\n",
    "    fc = Dense(256, activation='relu')(fc)\n",
    "    fc = Dropout(0.25)(fc)\n",
    "    fc = BatchNormalization()(fc)\n",
    "    fc = Dense(256, activation='relu')(fc)\n",
    "    fc = Dropout(0.25)(fc)\n",
    "    preds = Dense(6, activation = 'softmax')(fc)\n",
    "    \n",
    "    model = Model(inputs=_input, outputs=preds)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "    optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:  0\n",
      "23327 93297\n",
      "Train on 93297 samples, validate on 23327 samples\n",
      "Epoch 1/100\n",
      "93297/93297 [==============================] - 18s 198us/step - loss: 0.0928 - val_loss: 0.0321\n",
      "Epoch 2/100\n",
      "93297/93297 [==============================] - 15s 161us/step - loss: 0.0250 - val_loss: 0.0309\n",
      "Epoch 3/100\n",
      "93297/93297 [==============================] - 15s 163us/step - loss: 0.0207 - val_loss: 0.0332\n",
      "Epoch 4/100\n",
      "93297/93297 [==============================] - 15s 165us/step - loss: 0.0174 - val_loss: 0.0327\n",
      "Epoch 5/100\n",
      "93297/93297 [==============================] - 15s 160us/step - loss: 0.0163 - val_loss: 0.0332\n",
      "FOLD:  1\n",
      "23327 93297\n",
      "Train on 93297 samples, validate on 23327 samples\n",
      "Epoch 1/100\n",
      "93297/93297 [==============================] - 19s 199us/step - loss: 0.1444 - val_loss: 0.0345\n",
      "Epoch 2/100\n",
      "93297/93297 [==============================] - 15s 161us/step - loss: 0.0272 - val_loss: 0.0283\n",
      "Epoch 3/100\n",
      "93297/93297 [==============================] - 15s 163us/step - loss: 0.0209 - val_loss: 0.0268\n",
      "Epoch 4/100\n",
      "93297/93297 [==============================] - 15s 163us/step - loss: 0.0179 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "93297/93297 [==============================] - 15s 165us/step - loss: 0.0160 - val_loss: 0.0322\n",
      "Epoch 6/100\n",
      "93297/93297 [==============================] - 15s 161us/step - loss: 0.0148 - val_loss: 0.0299\n",
      "FOLD:  2\n",
      "23325 93299\n",
      "Train on 93299 samples, validate on 23325 samples\n",
      "Epoch 1/100\n",
      "93299/93299 [==============================] - 19s 203us/step - loss: 0.0995 - val_loss: 0.0308\n",
      "Epoch 2/100\n",
      "93299/93299 [==============================] - 15s 164us/step - loss: 0.0264 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "93299/93299 [==============================] - 15s 164us/step - loss: 0.0221 - val_loss: 0.0263\n",
      "Epoch 4/100\n",
      "93299/93299 [==============================] - 16s 167us/step - loss: 0.0176 - val_loss: 0.0244\n",
      "Epoch 5/100\n",
      "93299/93299 [==============================] - 15s 164us/step - loss: 0.0161 - val_loss: 0.0248\n",
      "Epoch 6/100\n",
      "93299/93299 [==============================] - 16s 167us/step - loss: 0.0139 - val_loss: 0.0266\n",
      "Epoch 7/100\n",
      "93299/93299 [==============================] - 15s 162us/step - loss: 0.0144 - val_loss: 0.0249\n",
      "FOLD:  3\n",
      "23323 93301\n",
      "Train on 93301 samples, validate on 23323 samples\n",
      "Epoch 1/100\n",
      "93301/93301 [==============================] - 19s 206us/step - loss: 0.1210 - val_loss: 0.0248\n",
      "Epoch 2/100\n",
      "93301/93301 [==============================] - 15s 164us/step - loss: 0.0261 - val_loss: 0.0285\n",
      "Epoch 3/100\n",
      "93301/93301 [==============================] - 15s 165us/step - loss: 0.0211 - val_loss: 0.0272\n",
      "Epoch 4/100\n",
      "93301/93301 [==============================] - 15s 164us/step - loss: 0.0171 - val_loss: 0.0280\n",
      "FOLD:  4\n",
      "23322 93302\n",
      "Train on 93302 samples, validate on 23322 samples\n",
      "Epoch 1/100\n",
      "93302/93302 [==============================] - 19s 208us/step - loss: 0.1073 - val_loss: 0.0326\n",
      "Epoch 2/100\n",
      "93302/93302 [==============================] - 15s 164us/step - loss: 0.0255 - val_loss: 0.0332\n",
      "Epoch 3/100\n",
      "93302/93302 [==============================] - 15s 163us/step - loss: 0.0200 - val_loss: 0.0304\n",
      "Epoch 4/100\n",
      "93302/93302 [==============================] - 15s 162us/step - loss: 0.0166 - val_loss: 0.0323\n",
      "Epoch 5/100\n",
      "93302/93302 [==============================] - 15s 164us/step - loss: 0.0153 - val_loss: 0.0339\n",
      "Epoch 6/100\n",
      "93302/93302 [==============================] - 15s 164us/step - loss: 0.0135 - val_loss: 0.0335\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "skf = StratifiedKFold(train_labels, n_folds=5, shuffle=True, random_state=42)\n",
    "train_labels_nn = pd.get_dummies(train_labels).values\n",
    "meta_train = np.zeros(shape = (len(train),6))\n",
    "meta_test = np.zeros(shape = (len(test),6))\n",
    "model_name = 'mlp_raw_feature_v2'\n",
    "for i,(tr_ind,te_ind) in enumerate(skf):\n",
    "    print 'FOLD: ',i\n",
    "    print len(te_ind),len(tr_ind)\n",
    "    X_train,X_train_label = train_nn[tr_ind],train_labels_nn[tr_ind]\n",
    "    X_val,X_val_label = train_nn[te_ind],train_labels_nn[te_ind] \n",
    "    \n",
    "    model_save_path = '../model_weight/{}.hdf5'.format(model_name)\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model_checkpoint = ModelCheckpoint(model_save_path, save_best_only=True, save_weights_only=True)\n",
    "    model = MLP_2()\n",
    "    model.fit(X_train,X_train_label,\n",
    "                  validation_data=(X_val,X_val_label),\n",
    "                  epochs=100,batch_size=512,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[early_stopping,model_checkpoint]\n",
    "            )\n",
    "    pred_val = model.predict(X_val)\n",
    "    pred_test = model.predict(test_nn)\n",
    "    \n",
    "    meta_train[te_ind] = pred_val\n",
    "    meta_test += pred_test\n",
    "meta_test /= 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(meta_train,'../feature/train_meta_mlp_2.pkl')\n",
    "pd.to_pickle(meta_test,'../feature/test_meta_mlp_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
